{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40da60d3-d2ef-4647-85af-284d322bc013",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kagglehub'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkagglehub\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Download latest version\u001b[39;00m\n\u001b[32m      3\u001b[39m path = kagglehub.dataset_download(\u001b[33m\"\u001b[39m\u001b[33mgopalbhattrai/pascal-voc-2012-dataset\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'kagglehub'"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"gopalbhattrai/pascal-voc-2012-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5334feb-256c-46a3-8083-7cbb97cefbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 02:58:48.822414: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/garvthakral/miniconda3/envs/yolo_gpu/lib/python3.11/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c644fd3a-e35a-49ae-bd8e-7ab6ae72f4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls /home/garvthakral/.cache/kagglehub/datasets/gopalbhattrai/pascal-voc-2012-dataset/versions/1/VOC2012_train_val/VOC2012_train_val/JPEGImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f7bd38c8-0117-48de-9aad-89cbbae1cdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/garvthakral/.cache/kagglehub/datasets/gopalbhattrai/pascal-voc-2012-dataset/versions/1/VOC2012_train_val/VOC2012_train_val/Annotations/2007_000027.xml\n"
     ]
    }
   ],
   "source": [
    "# !cat /home/garvthakral/.cache/kagglehub/datasets/gopalbhattrai/pascal-voc-2012-dataset/versions/1/VOC2012_train_val/VOC2012_train_val/ImageSets/Layout/train.txt\n",
    "!ls /home/garvthakral/.cache/kagglehub/datasets/gopalbhattrai/pascal-voc-2012-dataset/versions/1/VOC2012_train_val/VOC2012_train_val/Annotations/2007_000027.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a81e52f1-5bba-4265-9e22-32811213b009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person 174 101 349 351\n",
      "   Part: head 169 104 209 146\n",
      "   Part: hand 278 210 297 233\n",
      "   Part: foot 273 333 297 354\n",
      "   Part: foot 319 307 340 326\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "tree = ET.parse('/home/garvthakral/.cache/kagglehub/datasets/gopalbhattrai/pascal-voc-2012-dataset/versions/1/VOC2012_train_val/VOC2012_train_val/Annotations/2007_000027.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "for obj in root.findall('object'):\n",
    "    cls = obj.find('name').text\n",
    "    bndbox = obj.find('bndbox')\n",
    "    xmin = int(bndbox.find('xmin').text)\n",
    "    ymin = int(bndbox.find('ymin').text)\n",
    "    xmax = int(bndbox.find('xmax').text)\n",
    "    ymax = int(bndbox.find('ymax').text)\n",
    "    print(cls, xmin, ymin, xmax, ymax)\n",
    "\n",
    "    # Optional: parse parts if needed\n",
    "    for part in obj.findall('part'):\n",
    "        part_name = part.find('name').text\n",
    "        part_box = part.find('bndbox')\n",
    "        pxmin = int(part_box.find('xmin').text)\n",
    "        pymin = int(part_box.find('ymin').text)\n",
    "        pxmax = int(part_box.find('xmax').text)\n",
    "        pymax = int(part_box.find('ymax').text)\n",
    "        print('   Part:', part_name, pxmin, pymin, pxmax, pymax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9814e4a-8764-4151-b2b3-d01d6ebe30e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'supervision'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msupervision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msv\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcv2\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'supervision'"
     ]
    }
   ],
   "source": [
    "import supervision as sv\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def infer(imagePath,coordinates = None):\n",
    "    image = cv2.imread(imagePath)\n",
    "    \n",
    "    if coordinates == None:\n",
    "        return image\n",
    "    \n",
    "    detections = sv.Detections(\n",
    "        xyxy=np.array([coordinates]),\n",
    "        class_id=np.array([0]),\n",
    "        confidence=np.array([0.94])\n",
    "    )\n",
    "    \n",
    "    # Create annotator using current API\n",
    "    annotator = sv.BoxAnnotator()  # <- new name\n",
    "    annotated_frame = annotator.annotate(scene=image.copy(), detections=detections)\n",
    "    \n",
    "    return annotated_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "fa1bcafb-819e-4527-aa98-9d5599d9dc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sv.plot_image(infer(\"/home/garvthakral/.cache/kagglehub/datasets/gopalbhattrai/pascal-voc-2012-dataset/versions/1/VOC2012_train_val/VOC2012_train_val/JPEGImages/2007_000027.jpg\",coordinates= [174, 101, 349, 351]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72679ba6-12ca-4b0e-91a5-b04bb834c87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_label_map = {\n",
    "    0: \"background\",1: \"aeroplane\",2: \"bicycle\",3: \"bird\",4: \"boat\",\n",
    "    5: \"bottle\",6: \"bus\",7: \"car\",8: \"cat\",\n",
    "    9: \"chair\",10: \"cow\",11: \"diningtable\",12: \"dog\",\n",
    "    13: \"horse\",14: \"motorbike\",15: \"person\",16: \"pottedplant\",\n",
    "    17: \"sheep\",18: \"sofa\",19: \"train\",20: \"tvmonitor\"\n",
    "}\n",
    "label_to_id_map = {v:k for k,v in id_to_label_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffb32bb4-6ff6-45ee-b501-89114377a64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true,y_pred):\n",
    "    loss = tf.reduce_sum(tf.square(tf.subtract(y_true,y_pred)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc4dee45-1a66-4cf5-a974-b501a785c888",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1756330135.444879   13929 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4149 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "with open('/home/garvthakral/.cache/kagglehub/datasets/gopalbhattrai/pascal-voc-2012-dataset/versions/1/VOC2012_train_val/VOC2012_train_val/ImageSets/Main/train.txt','r') as f:\n",
    "    reader = f.read()\n",
    "train_arr = reader.split('\\n')\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_arr)\n",
    "with open('/home/garvthakral/.cache/kagglehub/datasets/gopalbhattrai/pascal-voc-2012-dataset/versions/1/VOC2012_train_val/VOC2012_train_val/ImageSets/Main/val.txt','r') as f:\n",
    "    reader = f.read()\n",
    "val_arr = reader.split('\\n')\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(val_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa0b0ae4-31a9-445c-97be-4ccfb53b3be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "def preprocess(image_id, img_dir, ann_dir):\n",
    "    img_path = tf.strings.join([img_dir, \"/\", image_id, \".jpg\"])\n",
    "    xml_path = tf.strings.join([ann_dir, \"/\", image_id, \".xml\"])\n",
    "\n",
    "    def _xmlparser(xml_path_str):\n",
    "        import xml.etree.ElementTree as ET\n",
    "        xml_path_str = xml_path_str.numpy().decode()  # convert bytes to str\n",
    "        tree = ET.parse(xml_path_str)\n",
    "        root = tree.getroot()\n",
    "        nameList, bndBoxList = [], []\n",
    "        for x in root.findall('object'):\n",
    "            nameList.append(x.find('name').text)\n",
    "            bndBoxList.append([int(y.text) for y in x.find('bndbox')])\n",
    "        # only take first object for simplicity\n",
    "        one_hot_class = tf.one_hot(label_to_id_map[nameList[0]], depth=20)\n",
    "        temp = tf.constant([1] + bndBoxList[0], dtype=tf.float32)\n",
    "        y_label = tf.concat([temp, one_hot_class], axis=0)\n",
    "        return y_label\n",
    "\n",
    "    y_label = tf.py_function(func=_xmlparser, inp=[xml_path], Tout=tf.float32)\n",
    "    y_label.set_shape([25])  # objectness + bbox + 20 classes\n",
    "\n",
    "    # Load and preprocess image\n",
    "    img_raw = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_jpeg(img_raw, channels=3)\n",
    "    img = tf.image.resize_with_pad(img, 448, 448)\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "\n",
    "    return img, y_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84f76d09-d57c-40b0-8615-3d8e2d1b6219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized bounding boxes:\n",
      " [[0.018      0.29234973 0.998      0.71857923]\n",
      " [0.842      0.5464481  0.964      0.61748636]\n",
      " [0.65       0.5136612  0.822      0.60928965]]\n",
      "Final label vector: [1.         0.018      0.29234973 0.998      0.71857923 0.\n",
      " 1.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tree = ET.parse('/home/garvthakral/.cache/kagglehub/datasets/gopalbhattrai/pascal-voc-2012-dataset/versions/1/VOC2012_train_val/VOC2012_train_val/Annotations/2007_000033.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "nameList = []\n",
    "bndBoxList = []\n",
    "\n",
    "# Get original image width and height\n",
    "size = root.find('size')\n",
    "W = int(size.find('width').text)\n",
    "H = int(size.find('height').text)\n",
    "\n",
    "# Extract objects + bounding boxes\n",
    "for x in root.findall('object'):\n",
    "    name = x.find('name').text\n",
    "    bndbox = x.find('bndbox')\n",
    "    xmin = int(bndbox.find('xmin').text)\n",
    "    ymin = int(bndbox.find('ymin').text)\n",
    "    xmax = int(bndbox.find('xmax').text)\n",
    "    ymax = int(bndbox.find('ymax').text)\n",
    "\n",
    "    # normalize using W, H\n",
    "    xmin /= W\n",
    "    xmax /= W\n",
    "    ymin /= H\n",
    "    ymax /= H\n",
    "\n",
    "    nameList.append(name)\n",
    "    bndBoxList.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "bndBoxList = np.array(bndBoxList, dtype=np.float32)\n",
    "print(\"Normalized bounding boxes:\\n\", bndBoxList)\n",
    "\n",
    "# Example: building label tensor for the first box\n",
    "for x in range(len(nameList)):\n",
    "    one_hot_class = tf.one_hot(label_to_id_map[nameList[x]], depth=20)\n",
    "    temp = tf.constant([1] + bndBoxList[x].tolist(), dtype=tf.float32)  # [objectness, xmin, ymin, xmax, ymax]\n",
    "    y_label = tf.concat([temp, one_hot_class], axis=0)\n",
    "    print(\"Final label vector:\", y_label.numpy())\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03f4792a-b567-426b-adf1-12bcaf34ae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = '/home/garvthakral/.cache/kagglehub/datasets/gopalbhattrai/pascal-voc-2012-dataset/versions/1/VOC2012_train_val/VOC2012_train_val/JPEGImages'\n",
    "ann_dir = '/home/garvthakral/.cache/kagglehub/datasets/gopalbhattrai/pascal-voc-2012-dataset/versions/1/VOC2012_train_val/VOC2012_train_val/Annotations'\n",
    "# for x in train_dataset.map(lambda x:preprocess(x,img_dir,ann_dir)).take(1):\n",
    "#     print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "53ade92a-c270-4e39-90d6-ceca74e07ddd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load_dataset() missing 4 required positional arguments: 'reader_func_other_args', 'output_types', 'output_shapes', and 'reader_func'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[117]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m image_dataset = tf.raw_ops.LoadDataset(\n\u001b[32m      2\u001b[39m     path =\u001b[33m\"\u001b[39m\u001b[33m/home/garvthakral/.cache/kagglehub/datasets/gopalbhattrai/pascal-voc-2012-dataset/versions/1/VOC2012_train_val/VOC2012_train_val/JPEGImages\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/yolo/lib/python3.13/site-packages/tensorflow/python/util/tf_export.py:377\u001b[39m, in \u001b[36mkwarg_only.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m args:\n\u001b[32m    371\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    372\u001b[39m       \u001b[33m'\u001b[39m\u001b[38;5;132;01m{f}\u001b[39;00m\u001b[33m only takes keyword args (possible keys: \u001b[39m\u001b[38;5;132;01m{kwargs}\u001b[39;00m\u001b[33m). \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    373\u001b[39m       \u001b[33m'\u001b[39m\u001b[33mPlease pass these args as kwargs instead.\u001b[39m\u001b[33m'\u001b[39m.format(\n\u001b[32m    374\u001b[39m           f=f.\u001b[34m__name__\u001b[39m, kwargs=f_argspec.args\n\u001b[32m    375\u001b[39m       )\n\u001b[32m    376\u001b[39m   )\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m f(**kwargs)\n",
      "\u001b[31mTypeError\u001b[39m: load_dataset() missing 4 required positional arguments: 'reader_func_other_args', 'output_types', 'output_shapes', and 'reader_func'"
     ]
    }
   ],
   "source": [
    "# image_dataset = tf.raw_ops.LoadDataset(\n",
    "#     path =\"/home/garvthakral/.cache/kagglehub/datasets/gopalbhattrai/pascal-voc-2012-dataset/versions/1/VOC2012_train_val/VOC2012_train_val/JPEGImages\",   \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47066e58-d5c3-476e-8114-b4ed96acf1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,825</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_4 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)             │        \u001b[38;5;34m12,825\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">539,001</span> (2.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m539,001\u001b[0m (2.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">538,009</span> (2.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m538,009\u001b[0m (2.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">992</span> (3.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m992\u001b[0m (3.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, LeakyReLU, MaxPooling2D, GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def TinyYOLO_Light(input_shape=(448, 448, 3), num_classes=20):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Layer 1\n",
    "    X = Conv2D(16, (3,3), strides=1, padding='same')(inputs)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = LeakyReLU(0.1)(X)\n",
    "    X = MaxPooling2D((2,2), strides=2)(X)\n",
    "\n",
    "    # Layer 2\n",
    "    X = Conv2D(32, (3,3), padding='same')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = LeakyReLU(0.1)(X)\n",
    "    X = MaxPooling2D((2,2), strides=2)(X)\n",
    "\n",
    "    # Layer 3\n",
    "    X = Conv2D(64, (3,3), padding='same')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = LeakyReLU(0.1)(X)\n",
    "    X = MaxPooling2D((2,2), strides=2)(X)\n",
    "\n",
    "    # Layer 4\n",
    "    X = Conv2D(128, (3,3), padding='same')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = LeakyReLU(0.1)(X)\n",
    "    X = MaxPooling2D((2,2), strides=2)(X)\n",
    "\n",
    "    # Layer 5\n",
    "    X = Conv2D(256, (3,3), padding='same')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = LeakyReLU(0.1)(X)\n",
    "    X = MaxPooling2D((2,2), strides=2)(X)\n",
    "\n",
    "    # Global Pooling instead of Flatten\n",
    "    X = GlobalAveragePooling2D()(X)\n",
    "\n",
    "    # Dense layers for predictions\n",
    "    X = Dense(512, activation='relu')(X)\n",
    "    outputs = Dense(5 + num_classes, activation='sigmoid')(X)  # [objectness, bx, by, bw, bh, class probs]\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "model = TinyYOLO_Light()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f19822-2201-44f6-a117-242ee16d1a53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a0e64a3-a37b-453a-948f-a08cdd0fcfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 02:59:11.441136: I external/local_xla/xla/service/service.cc:163] XLA service 0x731794003cc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-08-28 02:59:11.441175: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2025-08-28 02:59:11.523252: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-08-28 02:59:11.954982: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  21/5718\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m47s\u001b[0m 8ms/step - accuracy: 0.5933 - loss: 272272.9375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1756330155.612587   14015 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5711/5718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4908 - loss: 291592.9062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 02:59:57.780639: W tensorflow/core/framework/op_kernel.cc:1855] OP_REQUIRES failed at whole_file_read_ops.cc:117 : NOT_FOUND: /home/garvthakral/.cache/kagglehub/datasets/gopalbhattrai/pascal-voc-2012-dataset/versions/1/VOC2012_train_val/VOC2012_train_val/JPEGImages/.jpg; No such file or directory\n",
      "2025-08-28 02:59:57.783028: W tensorflow/core/framework/op_kernel.cc:1842] UNKNOWN: FileNotFoundError: [Errno 2] No such file or directory: '/home/garvthakral/.cache/kagglehub/datasets/gopalbhattrai/pascal-voc-2012-dataset/versions/1/VOC2012_train_val/VOC2012_train_val/Annotations/.xml'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/garvthakral/miniconda3/envs/yolo_gpu/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    return func(device, token, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/garvthakral/miniconda3/envs/yolo_gpu/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/garvthakral/miniconda3/envs/yolo_gpu/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n",
      "    ret = self._func(*args)\n",
      "          ^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/garvthakral/miniconda3/envs/yolo_gpu/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/tmp/__autograph_generated_filee69nve5r.py\", line 20, in _xmlparser\n",
      "    tree = ag__.converted_call(ag__.ld(ET).parse, (ag__.ld(xml_path_str),), None, fscope_1)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/garvthakral/miniconda3/envs/yolo_gpu/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py\", line 335, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options, False)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/garvthakral/miniconda3/envs/yolo_gpu/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py\", line 460, in _call_unconverted\n",
      "    return f(*args)\n",
      "           ^^^^^^^^\n",
      "\n",
      "  File \"/home/garvthakral/miniconda3/envs/yolo_gpu/lib/python3.11/xml/etree/ElementTree.py\", line 1219, in parse\n",
      "    tree.parse(source, parser)\n",
      "\n",
      "  File \"/home/garvthakral/miniconda3/envs/yolo_gpu/lib/python3.11/xml/etree/ElementTree.py\", line 570, in parse\n",
      "    source = open(source, \"rb\")\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/home/garvthakral/.cache/kagglehub/datasets/gopalbhattrai/pascal-voc-2012-dataset/versions/1/VOC2012_train_val/VOC2012_train_val/Annotations/.xml'\n",
      "\n",
      "\n",
      "2025-08-28 02:59:57.800074: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: NOT_FOUND: /home/garvthakral/.cache/kagglehub/datasets/gopalbhattrai/pascal-voc-2012-dataset/versions/1/VOC2012_train_val/VOC2012_train_val/JPEGImages/.jpg; No such file or directory\n",
      "\t [[{{node ReadFile}}]]\n",
      "\t [[IteratorGetNext]]\n",
      "2025-08-28 02:59:57.800124: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: NOT_FOUND: /home/garvthakral/.cache/kagglehub/datasets/gopalbhattrai/pascal-voc-2012-dataset/versions/1/VOC2012_train_val/VOC2012_train_val/JPEGImages/.jpg; No such file or directory\n",
      "\t [[{{node ReadFile}}]]\n",
      "\t [[IteratorGetNext]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2025-08-28 02:59:57.800177: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 13848547966202298289\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Graph execution error:\n\nDetected at node ReadFile defined at (most recent call last):\n<stack traces unavailable>\nDetected at node ReadFile defined at (most recent call last):\n<stack traces unavailable>\n2 root error(s) found.\n  (0) NOT_FOUND:  /home/garvthakral/.cache/kagglehub/datasets/gopalbhattrai/pascal-voc-2012-dataset/versions/1/VOC2012_train_val/VOC2012_train_val/JPEGImages/.jpg; No such file or directory\n\t [[{{node ReadFile}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n  (1) NOT_FOUND:  /home/garvthakral/.cache/kagglehub/datasets/gopalbhattrai/pascal-voc-2012-dataset/versions/1/VOC2012_train_val/VOC2012_train_val/JPEGImages/.jpg; No such file or directory\n\t [[{{node ReadFile}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_multi_step_on_iterator_5068]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFoundError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m train_dataset_x = train_dataset.map(\u001b[38;5;28;01mlambda\u001b[39;00m x:preprocess(x,img_dir,ann_dir)).batch(\u001b[32m1\u001b[39m).prefetch(tf.data.AUTOTUNE)\n\u001b[32m      2\u001b[39m model.compile(\n\u001b[32m      3\u001b[39m     loss = loss_function,\n\u001b[32m      4\u001b[39m     optimizer = \u001b[33m\"\u001b[39m\u001b[33madam\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m     metrics = [\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      6\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m model.fit(train_dataset_x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/yolo_gpu/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/yolo_gpu/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[32m     54\u001b[39m                                       inputs, attrs, num_outputs)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mNotFoundError\u001b[39m: Graph execution error:\n\nDetected at node ReadFile defined at (most recent call last):\n<stack traces unavailable>\nDetected at node ReadFile defined at (most recent call last):\n<stack traces unavailable>\n2 root error(s) found.\n  (0) NOT_FOUND:  /home/garvthakral/.cache/kagglehub/datasets/gopalbhattrai/pascal-voc-2012-dataset/versions/1/VOC2012_train_val/VOC2012_train_val/JPEGImages/.jpg; No such file or directory\n\t [[{{node ReadFile}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n  (1) NOT_FOUND:  /home/garvthakral/.cache/kagglehub/datasets/gopalbhattrai/pascal-voc-2012-dataset/versions/1/VOC2012_train_val/VOC2012_train_val/JPEGImages/.jpg; No such file or directory\n\t [[{{node ReadFile}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_multi_step_on_iterator_5068]"
     ]
    }
   ],
   "source": [
    "train_dataset_x = train_dataset.map(lambda x:preprocess(x,img_dir,ann_dir)).batch(1).prefetch(tf.data.AUTOTUNE)\n",
    "model.compile(\n",
    "    loss = loss_function,\n",
    "    optimizer = \"adam\",\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "model.fit(train_dataset_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3039aa8b-cb41-4bc8-9c74-fbe8149ae825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "607150da-1374-4449-8198-1215c17a026b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 TensorFlow GPU Debug Script\n",
      "This will help diagnose GPU detection issues\n",
      "\n",
      "==================================================\n",
      " SYSTEM INFORMATION\n",
      "==================================================\n",
      "OS: Linux 6.11.0-29-generic\n",
      "Python: 3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]\n",
      "Architecture: x86_64\n",
      "\n",
      "==================================================\n",
      " NVIDIA DRIVER CHECK\n",
      "==================================================\n",
      "✅ NVIDIA driver detected!\n",
      "GPU Information:\n",
      "  | NVIDIA-SMI 570.133.07             Driver Version: 570.133.07     CUDA Version: 12.8     |\n",
      "  |   0  NVIDIA GeForce RTX 3060 ...    Off |   00000000:01:00.0 Off |                  N/A |\n",
      "\n",
      "==================================================\n",
      " CUDA CHECK\n",
      "==================================================\n",
      "✅ CUDA Compiler (nvcc) found!\n",
      "  Cuda compilation tools, release 12.8, V12.8.61\n",
      "✅ CUDA installation found at: /usr/local/cuda\n",
      "\n",
      "CUDA Environment Variables:\n",
      "  PATH: /home/garvthakral/miniconda3/envs/yolo_gpu/bin:/usr/local/cuda-12.8/bin:/home/garvthakral/miniconda3/condabin:/home/garvthakral/.local/bin:/home/garvthakral/.pyenv/plugins/pyenv-virtualenv/shims:/home/garvthakral/.pyenv/shims:/home/garvthakral/.pyenv/bin:/home/garvthakral/.local/bin:/home/garvthakral/.nvm/versions/node/v20.12.2/bin:/home/garvthakral/.cargo/bin:/home/garvthakral/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/snap/bin\n",
      "  LD_LIBRARY_PATH: /usr/local/cuda-12.8/lib64:\n",
      "\n",
      "==================================================\n",
      " CUDNN CHECK\n",
      "==================================================\n",
      "❌ cuDNN headers not found!\n",
      "cuDNN libraries found:\n",
      "  /usr/include/x86_64-linux-gnu/cudnn_ops.h\n",
      "  /usr/include/x86_64-linux-gnu/cudnn_cnn.h\n",
      "  /usr/include/x86_64-linux-gnu/cudnn.h\n",
      "  /usr/include/x86_64-linux-gnu/cudnn_ops_v9.h\n",
      "  /usr/include/x86_64-linux-gnu/cudnn_adv.h\n",
      "\n",
      "==================================================\n",
      " TENSORFLOW CHECK\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 02:10:12.023065: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/garvthakral/miniconda3/envs/yolo_gpu/lib/python3.11/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ TensorFlow version: 2.20.0\n",
      "Built with CUDA: True\n",
      "Built with GPU support: True\n",
      "\n",
      "==================================================\n",
      " GPU DETECTION TEST\n",
      "==================================================\n",
      "All Physical Devices:\n",
      "  PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n",
      "  PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "\n",
      "GPU Devices Found: 1\n",
      "✅ GPU(s) detected by TensorFlow!\n",
      "  GPU 0: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "    Details: {'compute_capability': (8, 6), 'device_name': 'NVIDIA GeForce RTX 3060 Laptop GPU'}\n",
      "\n",
      "==================================================\n",
      " GPU MEMORY TEST\n",
      "==================================================\n",
      "Setting memory growth...\n",
      "✅ Memory growth configured!\n",
      "Running simple GPU computation test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1756327216.391939   16882 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4149 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GPU computation successful! Result: [[1. 3.]\n",
      " [3. 7.]]\n",
      "\n",
      "==================================================\n",
      " VERSION COMPATIBILITY CHECK\n",
      "==================================================\n",
      "TensorFlow-CUDA-cuDNN Compatibility:\n",
      "TensorFlow: 2.20.0\n",
      "Check TensorFlow docs for your version's requirements\n",
      "\n",
      "==================================================\n",
      " ADDITIONAL DIAGNOSTICS\n",
      "==================================================\n",
      "\n",
      "CUDA Runtime Version:\n",
      "  Error: cat: /usr/local/cuda/version.txt: No such file or directory\n",
      "\n",
      "GPU Memory Info:\n",
      "  memory.total [MiB], memory.used [MiB], memory.free [MiB]\n",
      "6144 MiB, 145 MiB, 5672 MiB\n",
      "\n",
      "NVIDIA Driver Version:\n",
      "  NVRM version: NVIDIA UNIX x86_64 Kernel Module  570.133.07  Fri Mar 14 13:12:07 UTC 2025\n",
      "GCC version:  gcc version 14.2.0 (Ubuntu 14.2.0-4ubuntu2)\n",
      "\n",
      "Python Site Packages:\n",
      "  ['/home/garvthakral/miniconda3/envs/yolo_gpu/lib/python3.11/site-packages']\n",
      "\n",
      "==================================================\n",
      " COMMON FIXES\n",
      "==================================================\n",
      "1. Install/Update NVIDIA drivers:\n",
      "   sudo apt update && sudo apt install nvidia-driver-XXX\n",
      "\n",
      "2. Install CUDA toolkit:\n",
      "   wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin\n",
      "   sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600\n",
      "   # Download and install CUDA from NVIDIA website\n",
      "\n",
      "3. Install TensorFlow with GPU support:\n",
      "   pip install tensorflow[and-cuda]  # TF 2.12+\n",
      "   # or pip install tensorflow-gpu  # Older versions\n",
      "\n",
      "4. Set environment variables:\n",
      "   export PATH=/usr/local/cuda/bin:$PATH\n",
      "   export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH\n",
      "\n",
      "5. Docker option (if all else fails):\n",
      "   docker run --gpus all -it tensorflow/tensorflow:latest-gpu python\n",
      "\n",
      "6. Restart system after driver installation!\n",
      "\n",
      "==================================================\n",
      " SUMMARY\n",
      "==================================================\n",
      "If you're still having issues:\n",
      "1. Check TensorFlow installation docs\n",
      "2. Consider using conda for easier dependency management\n",
      "3. Try the official TensorFlow Docker images\n",
      "4. Post the output of this script when asking for help\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "TensorFlow GPU Debug Script\n",
    "Comprehensive check for GPU detection issues\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import platform\n",
    "\n",
    "def print_section(title):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\" {title}\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "def run_command(cmd):\n",
    "    \"\"\"Run shell command and return output\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "        return result.stdout.strip(), result.stderr.strip()\n",
    "    except Exception as e:\n",
    "        return \"\", str(e)\n",
    "\n",
    "def check_system_info():\n",
    "    print_section(\"SYSTEM INFORMATION\")\n",
    "    print(f\"OS: {platform.system()} {platform.release()}\")\n",
    "    print(f\"Python: {sys.version}\")\n",
    "    print(f\"Architecture: {platform.machine()}\")\n",
    "    \n",
    "def check_nvidia_driver():\n",
    "    print_section(\"NVIDIA DRIVER CHECK\")\n",
    "    \n",
    "    stdout, stderr = run_command(\"nvidia-smi\")\n",
    "    if stdout:\n",
    "        print(\"✅ NVIDIA driver detected!\")\n",
    "        print(\"GPU Information:\")\n",
    "        lines = stdout.split('\\n')\n",
    "        for line in lines:\n",
    "            if 'NVIDIA-SMI' in line or 'GeForce' in line or 'Tesla' in line or 'RTX' in line or 'GTX' in line:\n",
    "                print(f\"  {line.strip()}\")\n",
    "    else:\n",
    "        print(\"❌ NVIDIA driver not found!\")\n",
    "        print(f\"Error: {stderr}\")\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def check_cuda():\n",
    "    print_section(\"CUDA CHECK\")\n",
    "    \n",
    "    # Check nvcc\n",
    "    stdout, stderr = run_command(\"nvcc --version\")\n",
    "    if stdout:\n",
    "        print(\"✅ CUDA Compiler (nvcc) found!\")\n",
    "        for line in stdout.split('\\n'):\n",
    "            if 'release' in line.lower():\n",
    "                print(f\"  {line.strip()}\")\n",
    "    else:\n",
    "        print(\"❌ CUDA Compiler (nvcc) not found!\")\n",
    "        print(\"Try: export PATH=/usr/local/cuda/bin:$PATH\")\n",
    "    \n",
    "    # Check CUDA installation path\n",
    "    cuda_paths = [\n",
    "        \"/usr/local/cuda\",\n",
    "        \"/opt/cuda\",\n",
    "        \"/usr/lib/cuda\"\n",
    "    ]\n",
    "    \n",
    "    for path in cuda_paths:\n",
    "        if os.path.exists(path):\n",
    "            print(f\"✅ CUDA installation found at: {path}\")\n",
    "            break\n",
    "    else:\n",
    "        print(\"❌ CUDA installation directory not found!\")\n",
    "    \n",
    "    # Check environment variables\n",
    "    print(\"\\nCUDA Environment Variables:\")\n",
    "    cuda_vars = [\"CUDA_HOME\", \"CUDA_PATH\", \"CUDA_ROOT\", \"PATH\", \"LD_LIBRARY_PATH\"]\n",
    "    for var in cuda_vars:\n",
    "        value = os.environ.get(var, \"Not set\")\n",
    "        if \"cuda\" in value.lower():\n",
    "            print(f\"  {var}: {value}\")\n",
    "\n",
    "def check_cudnn():\n",
    "    print_section(\"CUDNN CHECK\")\n",
    "    \n",
    "    # Check common cuDNN locations\n",
    "    cudnn_locations = [\n",
    "        \"/usr/local/cuda/include/cudnn.h\",\n",
    "        \"/usr/include/cudnn.h\",\n",
    "        \"/opt/cuda/include/cudnn.h\"\n",
    "    ]\n",
    "    \n",
    "    for location in cudnn_locations:\n",
    "        if os.path.exists(location):\n",
    "            print(f\"✅ cuDNN header found at: {location}\")\n",
    "            \n",
    "            # Try to get cuDNN version\n",
    "            stdout, _ = run_command(f\"cat {location} | grep CUDNN_MAJOR -A 2\")\n",
    "            if stdout:\n",
    "                print(\"cuDNN Version:\")\n",
    "                for line in stdout.split('\\n')[:3]:\n",
    "                    if 'CUDNN_' in line:\n",
    "                        print(f\"  {line.strip()}\")\n",
    "            break\n",
    "    else:\n",
    "        print(\"❌ cuDNN headers not found!\")\n",
    "        \n",
    "    # Check for cuDNN library\n",
    "    stdout, _ = run_command(\"find /usr -name '*cudnn*' 2>/dev/null | head -5\")\n",
    "    if stdout:\n",
    "        print(\"cuDNN libraries found:\")\n",
    "        for line in stdout.split('\\n'):\n",
    "            print(f\"  {line}\")\n",
    "\n",
    "def check_tensorflow():\n",
    "    print_section(\"TENSORFLOW CHECK\")\n",
    "    \n",
    "    try:\n",
    "        import tensorflow as tf\n",
    "        print(f\"✅ TensorFlow version: {tf.__version__}\")\n",
    "        \n",
    "        # Check if it's GPU-enabled build\n",
    "        print(f\"Built with CUDA: {tf.test.is_built_with_cuda()}\")\n",
    "        print(f\"Built with GPU support: {tf.test.is_built_with_gpu_support()}\")\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"❌ TensorFlow not installed!\")\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def check_gpu_detection():\n",
    "    print_section(\"GPU DETECTION TEST\")\n",
    "    \n",
    "    try:\n",
    "        import tensorflow as tf\n",
    "        \n",
    "        # List physical devices\n",
    "        physical_devices = tf.config.list_physical_devices()\n",
    "        print(\"All Physical Devices:\")\n",
    "        for device in physical_devices:\n",
    "            print(f\"  {device}\")\n",
    "        \n",
    "        # List GPU devices specifically\n",
    "        gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "        print(f\"\\nGPU Devices Found: {len(gpu_devices)}\")\n",
    "        \n",
    "        if gpu_devices:\n",
    "            print(\"✅ GPU(s) detected by TensorFlow!\")\n",
    "            for i, gpu in enumerate(gpu_devices):\n",
    "                print(f\"  GPU {i}: {gpu}\")\n",
    "                \n",
    "                # Get GPU details\n",
    "                try:\n",
    "                    gpu_details = tf.config.experimental.get_device_details(gpu)\n",
    "                    print(f\"    Details: {gpu_details}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"    Details unavailable: {e}\")\n",
    "            \n",
    "            return True\n",
    "        else:\n",
    "            print(\"❌ No GPU devices found by TensorFlow!\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error checking GPU detection: {e}\")\n",
    "        return False\n",
    "\n",
    "def check_memory_growth():\n",
    "    print_section(\"GPU MEMORY TEST\")\n",
    "    \n",
    "    try:\n",
    "        import tensorflow as tf\n",
    "        \n",
    "        gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "        if not gpu_devices:\n",
    "            print(\"❌ No GPUs to test memory on!\")\n",
    "            return\n",
    "        \n",
    "        print(\"Setting memory growth...\")\n",
    "        for gpu in gpu_devices:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        \n",
    "        print(\"✅ Memory growth configured!\")\n",
    "        \n",
    "        # Simple computation test\n",
    "        print(\"Running simple GPU computation test...\")\n",
    "        with tf.device('/GPU:0'):\n",
    "            a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "            b = tf.constant([[1.0, 1.0], [0.0, 1.0]])\n",
    "            c = tf.matmul(a, b)\n",
    "            print(f\"✅ GPU computation successful! Result: {c.numpy()}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ GPU memory/computation test failed: {e}\")\n",
    "\n",
    "def check_versions_compatibility():\n",
    "    print_section(\"VERSION COMPATIBILITY CHECK\")\n",
    "    \n",
    "    try:\n",
    "        import tensorflow as tf\n",
    "        \n",
    "        print(\"TensorFlow-CUDA-cuDNN Compatibility:\")\n",
    "        tf_version = tf.__version__\n",
    "        print(f\"TensorFlow: {tf_version}\")\n",
    "        \n",
    "        # Common compatible versions\n",
    "        compatibility = {\n",
    "            \"2.15.0\": {\"cuda\": \"12.2\", \"cudnn\": \"8.9\"},\n",
    "            \"2.14.0\": {\"cuda\": \"11.8\", \"cudnn\": \"8.7\"},\n",
    "            \"2.13.0\": {\"cuda\": \"11.8\", \"cudnn\": \"8.6\"},\n",
    "            \"2.12.0\": {\"cuda\": \"11.8\", \"cudnn\": \"8.6\"},\n",
    "            \"2.11.0\": {\"cuda\": \"11.2\", \"cudnn\": \"8.1\"},\n",
    "        }\n",
    "        \n",
    "        major_minor = '.'.join(tf_version.split('.')[:2]) + '.0'\n",
    "        if major_minor in compatibility:\n",
    "            req_cuda = compatibility[major_minor]['cuda']\n",
    "            req_cudnn = compatibility[major_minor]['cudnn']\n",
    "            print(f\"Recommended CUDA: {req_cuda}\")\n",
    "            print(f\"Recommended cuDNN: {req_cudnn}\")\n",
    "        else:\n",
    "            print(\"Check TensorFlow docs for your version's requirements\")\n",
    "            \n",
    "    except ImportError:\n",
    "        print(\"TensorFlow not available for version check\")\n",
    "\n",
    "def run_diagnostic_commands():\n",
    "    print_section(\"ADDITIONAL DIAGNOSTICS\")\n",
    "    \n",
    "    commands = {\n",
    "        \"CUDA Runtime Version\": \"cat /usr/local/cuda/version.txt\",\n",
    "        \"GPU Memory Info\": \"nvidia-smi --query-gpu=memory.total,memory.used,memory.free --format=csv\",\n",
    "        \"NVIDIA Driver Version\": \"cat /proc/driver/nvidia/version\",\n",
    "        \"Python Site Packages\": f\"python -c \\\"import site; print(site.getsitepackages())\\\"\",\n",
    "    }\n",
    "    \n",
    "    for name, cmd in commands.items():\n",
    "        stdout, stderr = run_command(cmd)\n",
    "        print(f\"\\n{name}:\")\n",
    "        if stdout:\n",
    "            print(f\"  {stdout}\")\n",
    "        elif stderr:\n",
    "            print(f\"  Error: {stderr}\")\n",
    "        else:\n",
    "            print(f\"  Command not available: {cmd}\")\n",
    "\n",
    "def suggest_fixes():\n",
    "    print_section(\"COMMON FIXES\")\n",
    "    \n",
    "    fixes = [\n",
    "        \"1. Install/Update NVIDIA drivers:\",\n",
    "        \"   sudo apt update && sudo apt install nvidia-driver-XXX\",\n",
    "        \"\",\n",
    "        \"2. Install CUDA toolkit:\",\n",
    "        \"   wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin\",\n",
    "        \"   sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600\",\n",
    "        \"   # Download and install CUDA from NVIDIA website\",\n",
    "        \"\",\n",
    "        \"3. Install TensorFlow with GPU support:\",\n",
    "        \"   pip install tensorflow[and-cuda]  # TF 2.12+\",\n",
    "        \"   # or pip install tensorflow-gpu  # Older versions\",\n",
    "        \"\",\n",
    "        \"4. Set environment variables:\",\n",
    "        \"   export PATH=/usr/local/cuda/bin:$PATH\",\n",
    "        \"   export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH\",\n",
    "        \"\",\n",
    "        \"5. Docker option (if all else fails):\",\n",
    "        \"   docker run --gpus all -it tensorflow/tensorflow:latest-gpu python\",\n",
    "        \"\",\n",
    "        \"6. Restart system after driver installation!\",\n",
    "    ]\n",
    "    \n",
    "    for fix in fixes:\n",
    "        print(fix)\n",
    "\n",
    "def main():\n",
    "    print(\"🔍 TensorFlow GPU Debug Script\")\n",
    "    print(\"This will help diagnose GPU detection issues\")\n",
    "    \n",
    "    # Run all checks\n",
    "    check_system_info()\n",
    "    \n",
    "    has_nvidia = check_nvidia_driver()\n",
    "    check_cuda()\n",
    "    check_cudnn()\n",
    "    \n",
    "    has_tf = check_tensorflow()\n",
    "    if has_tf:\n",
    "        has_gpu = check_gpu_detection()\n",
    "        if has_gpu:\n",
    "            check_memory_growth()\n",
    "        check_versions_compatibility()\n",
    "    \n",
    "    run_diagnostic_commands()\n",
    "    suggest_fixes()\n",
    "    \n",
    "    print_section(\"SUMMARY\")\n",
    "    print(\"If you're still having issues:\")\n",
    "    print(\"1. Check TensorFlow installation docs\")\n",
    "    print(\"2. Consider using conda for easier dependency management\")\n",
    "    print(\"3. Try the official TensorFlow Docker images\")\n",
    "    print(\"4. Post the output of this script when asking for help\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62f0311-bdea-47c5-a800-c2059e2e2db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y tensorflow\n",
    "\n",
    "!conda install -c conda-forge cudatoolkit cudnn\n",
    "!conda install -c conda-forge tensorflow-gpu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
